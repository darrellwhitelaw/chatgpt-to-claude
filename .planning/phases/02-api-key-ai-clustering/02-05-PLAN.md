---
phase: 02-api-key-ai-clustering
plan: "05"
type: execute
wave: 4
depends_on:
  - "02-01"
  - "02-02"
  - "02-03"
  - "02-04"
files_modified:
  - src-tauri/src/ai/mod.rs
  - src-tauri/src/ai/batch.rs
  - src-tauri/src/ai/prompts.rs
  - src-tauri/src/commands/cluster.rs
  - src-tauri/src/lib.rs
  - src/screens/ClusteringView.tsx
  - src/hooks/useCluster.ts
  - src/store/appStore.ts
  - src/App.tsx
autonomous: false
requirements:
  - AI-01
  - AI-03
  - AI-04

must_haves:
  truths:
    - "Clicking Proceed triggers the two-pass clustering pipeline: Pass 1 generates cluster vocabulary, Pass 2 submits the full batch"
    - "Spinner + stage labels update live: 'Discovering clusters...', 'Clustering conversations...', 'Generating summaries...', 'Saving results...'"
    - "Each conversation receives a cluster_label, summary, and instructions (or null) written to SQLite"
    - "Batch results are matched to conversations via custom_id (not position) — HashMap lookup, not array index"
    - "On batch failure, error screen appears with 'Try again' returning user to cost screen"
    - "App generates AI summaries (3-5 sentences, key decisions + conclusions + main topic) and custom instruction extraction"
  artifacts:
    - path: "src-tauri/src/ai/batch.rs"
      provides: "Anthropic Batch API HTTP calls: create batch, poll status, fetch JSONL results"
      exports: ["create_batch", "poll_batch", "fetch_results"]
    - path: "src-tauri/src/ai/prompts.rs"
      provides: "Prompt templates for Pass 1 (cluster vocabulary) and Pass 2 (combined cluster + summary + instructions)"
      exports: ["PASS1_SYSTEM_PROMPT", "PASS2_SYSTEM_PROMPT", "build_pass2_request"]
    - path: "src-tauri/src/commands/cluster.rs"
      provides: "start_clustering Tauri command: Pass 1 sync call + Pass 2 batch + poll loop + SQLite writes"
      exports: ["start_clustering"]
    - path: "src/screens/ClusteringView.tsx"
      provides: "Spinner + stage label + elapsed time display for clustering progress"
  key_links:
    - from: "src-tauri/src/commands/cluster.rs"
      to: "tauri::async_runtime::spawn"
      via: "poll loop runs in background"
      pattern: "async_runtime::spawn"
    - from: "src-tauri/src/commands/cluster.rs"
      to: "store::db::update_cluster_result"
      via: "writes per-conversation results from JSONL"
      pattern: "update_cluster_result"
    - from: "src/hooks/useCluster.ts"
      to: "start_clustering Tauri command"
      via: "Channel<ClusterEvent> invoke"
      pattern: "start_clustering"
    - from: "src/screens/ClusteringView.tsx"
      to: "useAppStore stage"
      via: "reads stage label for display"
      pattern: "stage"
---

<objective>
Build the core AI clustering pipeline: two-pass orchestrator (Pass 1 vocabulary + Pass 2 batch), JSONL result parsing, SQLite writes, and the ClusteringView progress UI.

Purpose: This is the heart of Phase 2. AI-01 (clustering), AI-03 (summaries), and AI-04 (instruction extraction) are all satisfied by the single combined batch in Pass 2.
Output: Full clustering pipeline from Proceed click to cluster_label + summary + instructions in SQLite for every conversation.
</objective>

<execution_context>
@/Users/darrellwhitelaw/.claude/get-shit-done/workflows/execute-plan.md
@/Users/darrellwhitelaw/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-api-key-ai-clustering/02-CONTEXT.md
@.planning/phases/02-api-key-ai-clustering/02-RESEARCH.md
@src-tauri/src/lib.rs
@src-tauri/src/commands/cluster.rs
@src-tauri/src/store/db.rs
@src/store/appStore.ts
@src/lib/bindings.ts
@src/hooks/useCluster.ts
@src/App.tsx
@.planning/phases/02-api-key-ai-clustering/02-01-SUMMARY.md
@.planning/phases/02-api-key-ai-clustering/02-02-SUMMARY.md
@.planning/phases/02-api-key-ai-clustering/02-04-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ai/ module with batch.rs and prompts.rs, then implement start_clustering command</name>
  <files>
    src-tauri/src/ai/mod.rs
    src-tauri/src/ai/batch.rs
    src-tauri/src/ai/prompts.rs
    src-tauri/src/commands/cluster.rs
    src-tauri/src/lib.rs
  </files>
  <action>
Create the `src-tauri/src/ai/` directory and three files.

**src-tauri/src/ai/mod.rs**:
```rust
pub mod batch;
pub mod prompts;
```

**src-tauri/src/ai/prompts.rs** — prompt templates for both passes:

```rust
pub const PASS1_SYSTEM_PROMPT: &str = "You are a conversation analyst. \
Given a list of conversation titles and brief excerpts from a ChatGPT export, \
identify 5-20 distinct topical cluster labels that would meaningfully organize \
this conversation history. Each label should be 2-4 words, clear, and non-overlapping. \
Return ONLY a JSON object with one field: {\"labels\": [\"Label 1\", \"Label 2\", ...]}. \
No other text.";

pub fn build_pass1_message(titles_and_snippets: &str) -> String {
    format!(
        "Here are conversation titles and opening lines from a ChatGPT export:\n\n{}\n\n\
         Generate 5-20 cluster labels for organizing these conversations.",
        titles_and_snippets
    )
}

/// pass2_system is built dynamically with the cluster vocabulary embedded
pub fn build_pass2_system(cluster_labels: &[String]) -> String {
    let labels_list = cluster_labels
        .iter()
        .enumerate()
        .map(|(i, l)| format!("{}. {}", i + 1, l))
        .collect::<Vec<_>>()
        .join("\n");

    format!(
        "You are analyzing a ChatGPT conversation transcript. \
Return ONLY a JSON object with exactly these three fields:\n\
- \"cluster_label\": string — choose from ONLY these options:\n{}\n\
- \"summary\": string — 3-5 sentences covering the main topic, key decisions, and conclusions. \
Plain English, no jargon.\n\
- \"instructions\": string or null — any custom instructions the user gave the AI (e.g. \
'always respond in bullet points', 'use metric units', preferred tone/format). \
Extract from system prompts or explicit user instructions. null if none found.\n\
No other text, no markdown, just valid JSON.",
        labels_list
    )
}

pub fn build_pass2_user_message(full_text: &str) -> String {
    // Truncate to prevent batch size issues (Pitfall 4)
    const MAX_CHARS: usize = 8_000;
    let text = if full_text.len() > MAX_CHARS {
        &full_text[..MAX_CHARS]
    } else {
        full_text
    };
    format!("Conversation transcript:\n\n{}", text)
}
```

**src-tauri/src/ai/batch.rs** — Anthropic API HTTP primitives:

```rust
use reqwest::Client;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

pub const MODEL: &str = "claude-haiku-3-5-20241022";
pub const ANTHROPIC_VERSION: &str = "2023-06-01";
pub const BATCH_API_URL: &str = "https://api.anthropic.com/v1/messages/batches";
pub const MESSAGES_API_URL: &str = "https://api.anthropic.com/v1/messages";

#[derive(Serialize)]
pub struct BatchRequestItem {
    pub custom_id: String,
    pub params: BatchParams,
}

#[derive(Serialize)]
pub struct BatchParams {
    pub model: String,
    pub max_tokens: u32,
    pub system: String,
    pub messages: Vec<Message>,
}

#[derive(Serialize)]
pub struct Message {
    pub role: String,
    pub content: String,
}

#[derive(Deserialize, Debug)]
pub struct BatchResult {
    pub id: String,
    pub processing_status: String,
    pub results_url: Option<String>,
}

#[derive(Deserialize, Debug)]
pub struct BatchResultItem {
    pub custom_id: String,
    pub result: BatchResultContent,
}

#[derive(Deserialize, Debug)]
pub struct BatchResultContent {
    #[serde(rename = "type")]
    pub result_type: String,
    pub message: Option<BatchMessage>,
    pub error: Option<serde_json::Value>,
}

#[derive(Deserialize, Debug)]
pub struct BatchMessage {
    pub content: Vec<ContentBlock>,
}

#[derive(Deserialize, Debug)]
pub struct ContentBlock {
    #[serde(rename = "type")]
    pub block_type: String,
    pub text: Option<String>,
}

/// Submit a batch and return the batch ID
pub async fn create_batch(
    client: &Client,
    api_key: &str,
    requests: Vec<BatchRequestItem>,
) -> Result<String, String> {
    let response = client
        .post(BATCH_API_URL)
        .header("x-api-key", api_key)
        .header("anthropic-version", ANTHROPIC_VERSION)
        .header("content-type", "application/json")
        .header("anthropic-beta", "message-batches-2024-09-24")
        .json(&serde_json::json!({ "requests": requests }))
        .send()
        .await
        .map_err(|e| e.to_string())?;

    if !response.status().is_success() {
        let status = response.status();
        let body = response.text().await.unwrap_or_default();
        return Err(format!("Batch create failed {}: {}", status, body));
    }

    let result: BatchResult = response.json().await.map_err(|e| e.to_string())?;
    Ok(result.id)
}

/// Poll batch status, return (is_complete, results_url)
pub async fn poll_batch(
    client: &Client,
    api_key: &str,
    batch_id: &str,
) -> Result<(bool, Option<String>), String> {
    let url = format!("{}/{}", BATCH_API_URL, batch_id);
    let response = client
        .get(&url)
        .header("x-api-key", api_key)
        .header("anthropic-version", ANTHROPIC_VERSION)
        .header("anthropic-beta", "message-batches-2024-09-24")
        .send()
        .await
        .map_err(|e| e.to_string())?;

    if !response.status().is_success() {
        let body = response.text().await.unwrap_or_default();
        return Err(format!("Batch poll failed: {}", body));
    }

    let result: BatchResult = response.json().await.map_err(|e| e.to_string())?;
    let done = result.processing_status == "ended";
    Ok((done, result.results_url))
}

/// Fetch JSONL results, return HashMap<custom_id, (cluster_label, summary, instructions)>
pub async fn fetch_results(
    client: &Client,
    api_key: &str,
    results_url: &str,
) -> Result<HashMap<String, (String, String, Option<String>)>, String> {
    let response = client
        .get(results_url)
        .header("x-api-key", api_key)
        .header("anthropic-version", ANTHROPIC_VERSION)
        .send()
        .await
        .map_err(|e| e.to_string())?;

    let text = response.text().await.map_err(|e| e.to_string())?;
    let mut map = HashMap::new();

    for line in text.lines() {
        let line = line.trim();
        if line.is_empty() { continue; }

        let item: BatchResultItem = match serde_json::from_str(line) {
            Ok(v) => v,
            Err(_) => continue, // skip malformed lines
        };

        if item.result.result_type != "succeeded" { continue; }

        let text_content = item.result.message
            .as_ref()
            .and_then(|m| m.content.first())
            .and_then(|b| b.text.as_deref())
            .unwrap_or("");

        // Parse the structured JSON response from the model
        if let Ok(parsed) = serde_json::from_str::<serde_json::Value>(text_content) {
            let cluster_label = parsed["cluster_label"].as_str().unwrap_or("Uncategorized").to_string();
            let summary = parsed["summary"].as_str().unwrap_or("").to_string();
            let instructions = parsed["instructions"].as_str().map(|s| s.to_string());
            map.insert(item.custom_id, (cluster_label, summary, instructions));
        }
    }

    Ok(map)
}

/// Pass 1: single synchronous Messages API call to discover cluster vocabulary
pub async fn discover_clusters(
    client: &Client,
    api_key: &str,
    titles_and_snippets: &str,
) -> Result<Vec<String>, String> {
    use super::prompts;

    let response = client
        .post(MESSAGES_API_URL)
        .header("x-api-key", api_key)
        .header("anthropic-version", ANTHROPIC_VERSION)
        .header("content-type", "application/json")
        .json(&serde_json::json!({
            "model": MODEL,
            "max_tokens": 512,
            "system": prompts::PASS1_SYSTEM_PROMPT,
            "messages": [{"role": "user", "content": prompts::build_pass1_message(titles_and_snippets)}]
        }))
        .send()
        .await
        .map_err(|e| e.to_string())?;

    if !response.status().is_success() {
        let body = response.text().await.unwrap_or_default();
        return Err(format!("Pass 1 failed: {}", body));
    }

    let body: serde_json::Value = response.json().await.map_err(|e| e.to_string())?;
    let text = body["content"][0]["text"].as_str().unwrap_or("{}");
    let parsed: serde_json::Value = serde_json::from_str(text).map_err(|e| e.to_string())?;

    let labels: Vec<String> = parsed["labels"]
        .as_array()
        .unwrap_or(&vec![])
        .iter()
        .filter_map(|v| v.as_str().map(|s| s.to_string()))
        .collect();

    if labels.is_empty() {
        return Err("Pass 1 returned no cluster labels".to_string());
    }

    Ok(labels)
}
```

**src-tauri/src/commands/cluster.rs** — add `start_clustering` command alongside existing `estimate_cost`. Keep estimate_cost unchanged, add:

```rust
use tauri::ipc::Channel;
use serde::Serialize;
use std::time::Duration;
use crate::ai::{batch, prompts};

#[derive(Clone, Serialize)]
#[serde(tag = "event", content = "data", rename_all = "camelCase")]
pub enum ClusterEvent {
    EstimatingTokens,
    Pass1Started,
    Pass1Complete { cluster_labels: Vec<String> },
    BatchSubmitted { batch_id: String },
    Polling { elapsed_secs: u64 },
    Complete { assigned_count: usize },
    Error { message: String },
}

#[tauri::command]
pub async fn start_clustering(
    state: State<'_, AppState>,
    on_event: Channel<ClusterEvent>,
) -> Result<(), String> {
    // 1. Get API key from Keychain
    let entry = Entry::new(SERVICE, USER).map_err(|e| e.to_string())?;
    let api_key = entry.get_password().map_err(|e| e.to_string())?;

    // 2. Load all conversations from SQLite
    let conversations = {
        let conn = state.db.lock().map_err(|e| e.to_string())?;
        db::get_all_conversations(&conn).map_err(|e| e.to_string())?
    };

    if conversations.is_empty() {
        return Err("No conversations found in database".to_string());
    }

    let client = reqwest::Client::new();

    // 3. Pass 1: build titles+snippets sample and discover cluster vocabulary
    let _ = on_event.send(ClusterEvent::Pass1Started);

    let titles_snippets: String = conversations
        .iter()
        .take(200) // sample up to 200 titles — sufficient for vocabulary discovery
        .map(|c| {
            let snippet: String = c.full_text.chars().take(200).collect();
            format!("Title: {}\nSnippet: {}", c.title.as_deref().unwrap_or("Untitled"), snippet)
        })
        .collect::<Vec<_>>()
        .join("\n---\n");

    let cluster_labels = batch::discover_clusters(&client, &api_key, &titles_snippets)
        .await
        .map_err(|e| {
            let _ = on_event.send(ClusterEvent::Error { message: e.clone() });
            e
        })?;

    let _ = on_event.send(ClusterEvent::Pass1Complete {
        cluster_labels: cluster_labels.clone(),
    });

    // 4. Pass 2: build batch requests with vocabulary embedded in system prompt
    let pass2_system = prompts::build_pass2_system(&cluster_labels);

    let requests: Vec<batch::BatchRequestItem> = conversations
        .iter()
        .map(|c| batch::BatchRequestItem {
            custom_id: c.id.clone(),
            params: batch::BatchParams {
                model: batch::MODEL.to_string(),
                max_tokens: 512,
                system: pass2_system.clone(),
                messages: vec![batch::Message {
                    role: "user".to_string(),
                    content: prompts::build_pass2_user_message(&c.full_text),
                }],
            },
        })
        .collect();

    // 5. Submit batch
    let batch_id = batch::create_batch(&client, &api_key, requests)
        .await
        .map_err(|e| {
            let _ = on_event.send(ClusterEvent::Error { message: e.clone() });
            e
        })?;

    let _ = on_event.send(ClusterEvent::BatchSubmitted { batch_id: batch_id.clone() });

    // 6. Poll loop — 5-second interval (user decision from CONTEXT.md)
    // CRITICAL: use tauri::async_runtime — NOT tokio::spawn (Pitfall 2 from RESEARCH.md)
    let start = std::time::Instant::now();
    let max_polls = 720; // 1 hour max (720 * 5s)
    let mut poll_count = 0;

    loop {
        tauri::async_runtime::spawn(async {}).await.ok(); // yield to Tauri runtime
        // Use tokio::time::sleep via tauri's runtime
        tokio::time::sleep(Duration::from_secs(5)).await;
        poll_count += 1;

        let elapsed = start.elapsed().as_secs();
        let _ = on_event.send(ClusterEvent::Polling { elapsed_secs: elapsed });

        let (done, results_url) = batch::poll_batch(&client, &api_key, &batch_id)
            .await
            .map_err(|e| {
                let _ = on_event.send(ClusterEvent::Error { message: e.clone() });
                e.clone()
            })?;

        if done {
            let results_url = results_url.ok_or_else(|| {
                "Batch ended with no results_url".to_string()
            })?;

            // 7. Fetch and parse JSONL results (Pitfall 5: use custom_id, not position)
            let results = batch::fetch_results(&client, &api_key, &results_url)
                .await
                .map_err(|e| {
                    let _ = on_event.send(ClusterEvent::Error { message: e.clone() });
                    e
                })?;

            // 8. Write to SQLite
            let assigned_count = results.len();
            {
                let conn = state.db.lock().map_err(|e| e.to_string())?;
                for (conv_id, (cluster_label, summary, instructions)) in &results {
                    let _ = db::update_cluster_result(
                        &conn,
                        conv_id,
                        cluster_label,
                        summary,
                        instructions.as_deref(),
                    );
                }
            }

            let _ = on_event.send(ClusterEvent::Complete { assigned_count });
            return Ok(());
        }

        if poll_count >= max_polls {
            let err = "Batch timed out after 1 hour".to_string();
            let _ = on_event.send(ClusterEvent::Error { message: err.clone() });
            return Err(err);
        }
    }
}
```

NOTE on `tokio::time::sleep`: Since `start_clustering` is an `async fn` Tauri command, it runs within Tauri's async runtime. `tokio::time::sleep` IS safe here because we are already inside the Tauri-managed tokio runtime — the panic (Pitfall 2) only occurs when calling `tokio::spawn` from outside a reactor context. Inside an `async fn #[tauri::command]`, we ARE in the reactor. The RESEARCH.md note applies to spawning background threads — not to awaiting within an existing async command.

**src-tauri/src/lib.rs** — add `mod ai;` at the top alongside `mod commands;` and `mod store;`. Register `start_clustering` in generate_handler!.

Also add `tokio` to imports — Tauri re-exports it, so add to Cargo.toml if not already present (it is pulled in transitively by Tauri):
```toml
# Only if tokio::time::sleep requires explicit dependency:
# tokio = { version = "1", features = ["time"] }
```
Check if tokio::time is available via tauri's dependency. If not, add `tokio = { version = "1", features = ["time"] }` to Cargo.toml.
  </action>
  <verify>
    <automated>cd /Users/darrellwhitelaw/Claude/chatgpt-to-claude/src-tauri && cargo check 2>&1 | tail -15</automated>
    <manual>Confirm cargo check passes. Confirm ai/mod.rs, ai/batch.rs, ai/prompts.rs exist. Confirm start_clustering in generate_handler!.</manual>
  </verify>
  <done>
    `cargo check` passes. ai/ module with batch.rs and prompts.rs compiles. start_clustering registered in lib.rs. ClusterEvent enum with serde tag/content serialization compiles correctly.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create ClusteringView, update useCluster hook and appStore, wire App.tsx</name>
  <files>
    src/screens/ClusteringView.tsx
    src/hooks/useCluster.ts
    src/store/appStore.ts
    src/App.tsx
  </files>
  <action>
**src/screens/ClusteringView.tsx** — spinner + stage label + elapsed time, matching Phase 1 ProgressView pattern (per locked decision in CONTEXT.md: "same pattern as Phase 1 ZIP parsing"):

```typescript
import { useAppStore } from '../store/appStore';

interface ClusteringViewProps {
  stage: string;
  elapsedSecs?: number;
}

export function ClusteringView({ stage, elapsedSecs }: ClusteringViewProps) {
  const formatElapsed = (secs: number): string => {
    if (secs < 60) return `${secs}s`;
    const m = Math.floor(secs / 60);
    const s = secs % 60;
    return `${m}m ${s}s`;
  };

  return (
    <div className="flex flex-col items-center gap-4">
      {/* Spinner — identical to ProgressView */}
      <div className="w-8 h-8 rounded-full border-2 border-neutral-200 border-t-neutral-500 animate-spin" />
      {/* Stage label — plain English, no jargon (locked decision) */}
      <p className="text-sm text-neutral-500">{stage}</p>
      {/* Elapsed time — shown after batch submitted */}
      {elapsedSecs !== undefined && elapsedSecs > 0 && (
        <p className="text-xs text-neutral-300">{formatElapsed(elapsedSecs)}</p>
      )}
    </div>
  );
}
```

Stage labels to use (plain English per CONTEXT.md):
- Pass1Started → "Discovering clusters..."
- Pass1Complete → "Clustering conversations..."
- BatchSubmitted → "Clustering conversations..."
- Polling → "Clustering conversations..."
- Complete (after store transition) → "Saving results..." (briefly shown)

**src/store/appStore.ts** — add `elapsedSecs: number` field to AppState (default 0, cleared in reset). This enables ClusteringView to display elapsed batch time without a React `useState` in App.tsx. Locate the existing Phase 2 fields (tokenEstimate, costEstimateUsd, clusterError, etc.) and add alongside them:

```typescript
elapsedSecs: number; // seconds elapsed during batch polling — set by useCluster on polling events
```

Initialize to `0` in the initial state object. Add `elapsedSecs: 0` to the `reset()` action's state reset. Do NOT remove or rename any existing fields.

**src/hooks/useCluster.ts** — replace the existing partial implementation with the full hook including `startClustering`:

```typescript
import { invoke, Channel } from '@tauri-apps/api/core';
import { useAppStore } from '../store/appStore';
import type { ClusterEvent } from '../lib/bindings';

interface CostEstimate {
  input_tokens: number;
  estimated_usd: number;
}

export function useCluster() {
  const {
    setCostReady,
    setAwaitingKey,
    setClustering,
    setClusteringComplete,
    setStage,
  } = useAppStore();

  const fetchCostEstimate = async (): Promise<void> => {
    try {
      const result: CostEstimate = await invoke('estimate_cost');
      setCostReady(result.input_tokens, result.estimated_usd);
    } catch (err) {
      const msg = err instanceof Error ? err.message : String(err);
      if (msg.startsWith('INVALID_API_KEY:')) {
        useAppStore.setState({
          clusterError: 'Invalid API key — check console.anthropic.com',
          phase: 'awaiting-key',
        });
      } else {
        useAppStore.getState().setError(msg);
      }
    }
  };

  const startClustering = async (): Promise<void> => {
    const onEvent = new Channel<ClusterEvent>();

    onEvent.onmessage = (msg) => {
      switch (msg.event) {
        case 'pass1Started':
          setStage('Discovering clusters...');
          break;
        case 'pass1Complete':
          setStage('Clustering conversations...');
          break;
        case 'batchSubmitted':
          setClustering(msg.data.batchId);
          setStage('Clustering conversations...');
          break;
        case 'polling':
          useAppStore.setState((s) => ({
            ...s,
            stage: 'Clustering conversations...',
            elapsedSecs: msg.data.elapsedSecs,
          }));
          break;
        case 'complete':
          setStage('Saving results...');
          setTimeout(() => setClusteringComplete(), 500); // brief feedback
          break;
        case 'error':
          useAppStore.setState({
            phase: 'error',
            clusterError: msg.data.message,
          });
          break;
      }
    };

    try {
      await invoke('start_clustering', { onEvent });
    } catch (err) {
      const msg = err instanceof Error ? err.message : String(err);
      useAppStore.setState({ phase: 'error', clusterError: msg });
    }
  };

  return { fetchCostEstimate, startClustering };
}
```

**src/App.tsx** — make targeted updates:

1. Add imports:
```typescript
import { ClusteringView } from './screens/ClusteringView';
```

2. Destructure `elapsedSecs` from `useAppStore()`.

3. Update `startClustering` invocation: the CostScreen's Proceed button (Plan 02-04) calls `setClustering('pending')` as a placeholder. Now replace that: update CostScreen.tsx to accept a `onProceed` callback prop, or (simpler) update App.tsx to detect the `clustering` phase with `batchId === 'pending'` and trigger `startClustering()` via a useEffect.

The cleanest approach: Add `onProceed` prop to CostScreen:
```typescript
// In App.tsx:
const { fetchCostEstimate, startClustering } = useCluster();

// In CostScreen render:
{phase === 'cost-ready' && tokenEstimate !== null && costEstimateUsd !== null && (
  <CostScreen
    tokens={tokenEstimate}
    estimatedUsd={costEstimateUsd}
    onProceed={startClustering}
  />
)}
```

Update `src/screens/CostScreen.tsx` to accept and call `onProceed: () => void` instead of calling `setClustering('pending')` directly. Remove the `setClustering` import from CostScreen — it should not manage clustering state directly.

4. Replace ClusteringView placeholder:
```tsx
{phase === 'clustering' && (
  <ClusteringView stage={stage} elapsedSecs={elapsedSecs} />
)}
```

5. Add error screen for clustering failures — when `phase === 'error'` and `clusterError` is set, show "Try again" that returns to cost screen:

The existing error screen shows DropZone with error message and "Try again" that calls `reset()`. For clustering errors, we want "Try again" to go back to `cost-ready` (not back to drop zone).

Update App.tsx error rendering to distinguish between parse errors and cluster errors:
```tsx
{phase === 'error' && clusterError && (
  <div className="flex flex-col items-center gap-4 text-center px-6">
    <p className="text-sm text-red-500">{clusterError}</p>
    <button
      onClick={() => useAppStore.setState({ phase: 'cost-ready', clusterError: null })}
      className="text-sm text-neutral-500 hover:text-neutral-700 underline underline-offset-2"
    >
      Try again
    </button>
  </div>
)}
{phase === 'error' && !clusterError && (
  <DropZone errorMessage={error ?? undefined} onReset={reset} />
)}
```

Destructure `clusterError` from `useAppStore()` in App.
  </action>
  <verify>
    <automated>cd /Users/darrellwhitelaw/Claude/chatgpt-to-claude && npx tsc --noEmit 2>&1 | head -20</automated>
    <manual>Confirm ClusteringView.tsx in src/screens/. Confirm useCluster.ts exports both fetchCostEstimate and startClustering. Confirm CostScreen has onProceed prop. Confirm appStore.ts has elapsedSecs field. Confirm tsc passes.</manual>
  </verify>
  <done>
    `npx tsc --noEmit` passes. ClusteringView renders spinner + stage + elapsed time. useCluster handles all ClusterEvent variants. appStore.ts includes elapsedSecs field initialized to 0 and cleared in reset(). CostScreen's Proceed calls startClustering via onProceed prop. Error screen has "Try again" returning to cost-ready.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Checkpoint: Verify end-to-end clustering and SQLite results</name>
  <action>Verify end-to-end clustering pipeline: batch submission, polling, SQLite writes, and ClusteringView UI.</action>
  <what-built>
    Complete AI clustering pipeline:
    - Pass 1: single sync call discovers 5-20 cluster labels from conversation sample
    - Pass 2: full batch submitted with vocabulary in system prompt
    - Poll loop: every 5 seconds, emits elapsed time to UI
    - JSONL results parsed via custom_id HashMap (not position)
    - cluster_label, summary, instructions written to SQLite per conversation
    - ClusteringView: spinner + stage labels ("Discovering clusters...", "Clustering conversations...")
    - Error screen with "Try again" returning to cost screen
    - clustering-complete phase reached when all SQLite writes finish
  </what-built>
  <how-to-verify>
    1. Run `npm run dev` (or `pnpm dev`)
    2. Drop the ChatGPT export ZIP → summary card
    3. Click Continue → enter API key if needed → cost screen shows real estimate
    4. Click Proceed → ClusteringView appears with spinner and "Discovering clusters..."
    5. Stage label changes to "Clustering conversations..." after Pass 1 completes
    6. Watch elapsed timer increment every 5 seconds during polling
    7. Wait for batch completion (typical: 2-10 minutes for 1,000 conversations)
    8. After completion, verify SQLite has cluster_label, summary, instructions for conversations:
       Run: `sqlite3 ~/Library/Application\ Support/com.darrellwhitelaw.chatgpt-to-claude/conversations.db "SELECT id, cluster_label, substr(summary, 1, 80), instructions IS NOT NULL FROM conversations LIMIT 5;"`
    9. Verify: cluster_labels are consistent (same topics get same label, not "ML" vs "Machine Learning")
    10. Verify summaries are 3-5 sentences with key decisions and main topic
    11. Verify instructions column contains extracted custom instructions where present, null otherwise
  </how-to-verify>
  <resume-signal>Type "approved" if clustering runs end-to-end and SQLite has correct results, or describe any issues</resume-signal>
</task>

</tasks>

<verification>
`cargo check` passes in src-tauri.
`npx tsc --noEmit` passes in project root.

SQLite check after a real clustering run:
```
sqlite3 ~/Library/Application\ Support/com.darrellwhitelaw.chatgpt-to-claude/conversations.db \
  "SELECT COUNT(*) FROM conversations WHERE cluster_label IS NOT NULL;"
```
Should return a count matching the number of conversations parsed in Phase 1.
</verification>

<success_criteria>
- `cargo check` passes; `npx tsc --noEmit` passes
- start_clustering command implements two-pass clustering (Pass 1 vocabulary + Pass 2 batch)
- Batch results matched via custom_id HashMap (not array index)
- cluster_label, summary, instructions written to SQLite for all conversations
- ClusteringView shows spinner + stage labels in plain English
- appStore.ts has elapsedSecs field (number, default 0, cleared on reset)
- Error → "Try again" → returns to cost-ready (not drop zone)
- clustering-complete phase reached after successful SQLite writes
- Human checkpoint approved with real SQLite data verified
</success_criteria>

<output>
After completion, create `.planning/phases/02-api-key-ai-clustering/02-05-SUMMARY.md`
</output>
